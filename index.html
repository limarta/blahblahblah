<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-time Face Censor</title>
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ”’</text></svg>">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;500;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Roboto', sans-serif;
            margin: 0;
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh; /* Use min-height to ensure full viewport coverage */
            background-color: #e3f2fd; /* A softer, more modern background color */
            color: #333; /* Darker text for better readability */
            overflow: hidden; /* Prevent scrollbars */
        }

        .container {
            position: relative;
            width: 90%; /* Adjust width for responsiveness */
            max-width: 800px;
            box-shadow: 0 8px 24px rgba(0, 0, 0, 0.1); /* More pronounced shadow */
            border-radius: 16px; /* Even more rounded corners */
            overflow: hidden;
            background-color: #fff; /* Clean white container */
            padding: 20px; /* Add some padding inside the container */
            box-sizing: border-box; /* Ensure padding doesn't increase container size */
        }

        #webcamVideo, #outputCanvas {
            display: block; /* Prevent extra space below inline elements */
            width: 100%; /* Make video and canvas responsive within the container */
            aspect-ratio: 6 / 4; /* Maintain aspect ratio */
        }

        #outputCanvas {
            position: absolute;
            top: 0;
            left: 0;
        }

        #loading {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            background-color: rgba(255, 255, 255, 0.9); /* Slightly less transparent */
            padding: 24px; /* Increased padding */
            border-radius: 12px;
            font-size: 1.1em; /* Slightly larger font */
            font-weight: 500; /* Semi-bold for emphasis */
            z-index: 3;
            display: none;
            box-shadow: 0 4px 10px rgba(0, 0, 0, 0.1);
        }

        #instructions {
            position: absolute;
            bottom: 30px; /* More space from the bottom */
            left: 50%;
            transform: translateX(-50%);
            background-color: #f8f9fa; /* Light gray background */
            color: #555; /* Slightly lighter text */
            padding: 16px 24px; /* Increased padding */
            border-radius: 20px; /* More rounded */
            font-size: 1em;
            z-index: 3;
            text-align: center;
            box-shadow: 0 3px 8px rgba(0, 0, 0, 0.08);
            border: 1px solid #eee; /* Light border */
        }

        #error {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            background-color: #ffebee; /* Light red background */
            color: #d32f2f; /* Darker red text */
            padding: 24px;
            border-radius: 12px;
            font-size: 1.1em;
            font-weight: 500;
            z-index: 3;
            display: none;
            box-shadow: 0 4px 10px rgba(0, 0, 0, 0.1);
            border: 1px solid #ef9a9a; /* Lighter red border */
            text-align: center;
        }
    </style>
</head>
<body>
    <div class="container">
        <video id="webcamVideo" autoplay playsinline muted style="transform: scaleX(-1);"></video>
        <canvas id="outputCanvas" style="transform: scaleX(-1);"></canvas>
        <div id="loading">Loading Face Detection Model...</div>
        <div id="instructions">Please grant webcam access. Face censoring will start automatically.</div>
        <div id="error"></div>
    </div>
    <div id="controls" style="position: absolute; bottom: 10px; left: 50%; transform: translateX(-50%); display: flex; gap: 10px;">
        <button id="recordButton" style="padding: 10px 20px; font-size: 1em;  background-color: #ccc;" disabled>
            Record
        </button>
        <button id="downloadButton" style="padding: 10px 20px; font-size: 1em; background-color: #ccc;" disabled>
            Download
        </button>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface@0.0.7/dist/blazeface.min.js"></script>
    <script>
        const videoElement = document.getElementById('webcamVideo');
        const canvasElement = document.getElementById('outputCanvas');
        const canvasContext = canvasElement.getContext('2d');
        const loadingElement = document.getElementById('loading');
        const instructionsElement = document.getElementById('instructions');
        const errorElement = document.getElementById('error');
        const recordButton = document.getElementById('recordButton');
        const downloadButton = document.getElementById('downloadButton');

        let model = null;
        let isRunning = false;
        let mediaRecorder = null;
        let recordedChunks = [];

        async function setupWebcam() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' } });
                videoElement.srcObject = stream;
                videoElement.onloadedmetadata = () => {
                    videoElement.play();
                    canvasElement.width = videoElement.videoWidth;
                    canvasElement.height = videoElement.videoHeight;
                    startFaceDetection();
                };
            } catch (err) {
                console.error("Error accessing the webcam:", err);
                errorElement.textContent = `Error accessing webcam: ${err.message}`;
                errorElement.style.display = 'block';
                loadingElement.style.display = 'none';
                instructionsElement.style.display = 'none';
            }
        }

        async function loadBlazefaceModel() {
            loadingElement.style.display = 'block';
            try {
                model = await blazeface.load();
                loadingElement.style.display = 'none';
                recordButton.disabled = false;
            } catch (error) {
                console.error("Failed to load model:", error);
                errorElement.textContent = "Failed to load the face detection model. Please check your network connection.";
                errorElement.style.display = 'block';
                loadingElement.style.display = 'none';
                instructionsElement.style.display = 'none';
                return;
            }
        }

        async function detectFaces() {
            try {
                if (model) {
                    const predictions = await model.estimateFaces(videoElement, false);

                    canvasContext.clearRect(0, 0, canvasElement.width, canvasElement.height);
                    canvasContext.drawImage(videoElement, 0, 0, canvasElement.width, canvasElement.height);

                    predictions.forEach(prediction => {
                        const start = prediction.topLeft;
                        const end = prediction.bottomRight;
                        const width = end[0] - start[0];
                        const height = end[1] - start[1];
                        canvasContext.fillStyle = 'black'; 
                        canvasContext.fillRect(start[0], start[1], width, height);
                    });
                    
                }
                if (isRunning) {
                    requestAnimationFrame(detectFaces);
                }
            } catch (error) {
                isRunning = false;
                errorElement.textContent = "Error during face detection. The application has stopped.";
                errorElement.style.display = 'block';
                console.error("Detection error:", error);
            }
        }

        function startFaceDetection() {
            if (!isRunning) {
                isRunning = true;
                instructionsElement.style.display = 'none';
                detectFaces();
            }
        }

        function startRecording() {
            const stream = canvasElement.captureStream();
            mediaRecorder = new MediaRecorder(stream);
            recordedChunks = [];

            mediaRecorder.ondataavailable = (event) => {
                if (event.data.size > 0) {
                    recordedChunks.push(event.data);
                }
            };

            mediaRecorder.onstop = () => {
                const blob = new Blob(recordedChunks, { type: 'video/webm' });
                const url = URL.createObjectURL(blob);
                downloadButton.href = url;
                downloadButton.download = 'censored-video.webm';
                downloadButton.style.cursor = 'pointer';
                downloadButton.style.backgroundColor = '';
                downloadButton.disabled = false;
            };

            mediaRecorder.start();
            recordButton.textContent = 'Stop Recording';
        }
        function stopRecording() {
            mediaRecorder.stop();
            recordButton.textContent = 'Record';
        }

        recordButton.addEventListener('click', () => {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                stopRecording();
            } else {
                startRecording();
            }
        });

        (async () => {
            await setupWebcam();
            await loadBlazefaceModel();
        })();
    </script>
</body>
</html>